even <- paste0(even, vector[j])
} else {
odd <- paste0(odd, vector[j])
}
}
print(paste(odd, even))
} else {
next
}
}
vec <- c(as.character(2), "Hacker", "Rank")
for (i in 1:length(vec)) {
if (length(vec[i]) > 1) {
vector <- strsplit(vec[i], "")[[1]]
even <- ""
odd <- ""
for (j in 1:length(vector)) {
if (i %% 2 == 0) {
even <- paste0(even, vector[j])
} else {
odd <- paste0(odd, vector[j])
}
}
print(paste(odd, even))
} else {
next
}
}
for (i in 2:length(vec)) {
if (length(vec[i]) > 1) {
vector <- strsplit(vec[i], "")[[1]]
even <- ""
odd <- ""
for (j in 1:length(vector)) {
if (i %% 2 == 0) {
even <- paste0(even, vector[j])
} else {
odd <- paste0(odd, vector[j])
}
}
print(paste(odd, even))
} else {
next
}
}
test(vec[2])
test(vec[1])
test
length("2")
length("21")
length("21h")
vec <- c("2", "Hacker", "Rank")
test <- function(vector) {
vector <- strsplit(vector, "")[[1]]
even <- ""
odd <- ""
for (i in 1:length(vector)) {
if (i %% 2 == 0) {
even <- paste0(even, vector[i])
} else {
odd <- paste0(odd, vector[i])
}
}
return(paste(odd, even))
}
for (i in 1:length(vec)) {
if (nchar(vec[i]) > 1) {
write(test(vec[i]), stdout())
} else {
next
}
}
Data_Frame <- read.table(“https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data“,
encoding=“UTF-16”, fill = TRUE, header = FALSE)
Data_Frame <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding=“UTF-16”, fill = TRUE, header = FALSE)
Data_Frame <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = FALSE)
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = FALSE)
rm(Data_Frame)
View(test)
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = TRUE)
test <- readLines("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data")
head(test)
test <- readLines("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\")
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\")
)
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\")
)))
w
w11
k
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data",
encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\")
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data")#,
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data")#,
#encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\")
source('~/.active-rstudio-document', echo=TRUE)
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data", encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\")
)
n
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data", encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\t")
test
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data", encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\n")
head(test)
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data", encoding="UTF-16", fill = TRUE, header = TRUE, sep = "\,")
test <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data", encoding="UTF-16", fill = TRUE, header = TRUE, sep = ",")
head(test)
names(df) <- c("recency", "frequency", "total_blood", "months_since_first_donation", "donation_march_2007")
df <- read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/blood-transfusion/transfusion.data", encoding="UTF-16", fill = TRUE, header = TRUE, sep = ",")
names(df) <- c("recency", "frequency", "total_blood", "months_since_first_donation", "donation_march_2007")
df
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
defaults write org.R-project.R force.LANG en_US.UTF-8
Sys.setlocale()
Sys.setlocale"("LC_CTYPE"")
Sys.setlocale("LC_CTYPE")
install.packages(c("MASS", "survival"))
Sys.setenv(LANG="en_US.UTF-8")
Sys.setenv(LC_ALL="en_US.UTF-8")
install.packages("tidyverse")
setwd("~/Documents/Education/Machine-Learning-Projects/K-Means_Clustering/")
customers <- read.csv("customers_bikeshops.csv")
orders <- read.csv("orders.csv")
products <- read.csv("products_bikes.csv")
head(customers)
head(orders)
head(products)
?inner_join
library(tidyverse)
library(tidyverse)
?inner_join
bike_data <- inner_join(customers, orders_products, by = c("bikeshop.id", "customer.id"))
customers <- read.csv("customers_bikeshops.csv")
orders <- read.csv("orders.csv")
products <- read.csv("products_bikes.csv")
# Merge datasets
# --------------
orders_products <- inner_join(orders, products, by = c("product.id", "bike.id"))
bike_data <- inner_join(customers, orders_products, by = c("bikeshop.id", "customer.id"))
?inner_join
orders_products <- inner_join(orders, products, by = c("product.id" = "bike.id"))
bike_data <- inner_join(customers, orders_products, by = c("bikeshop.id" = "customer.id"))
bike_data <- inner_join(customers, orders_products, by = c("bikeshop.id" = "customer.id"))
View(bike_data)
install.packages("corrplot")
library(corrplot)
corrplot(bike_data)
corrplot(as.matrix(bike_data))
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales)
View(cluster_data)
spread(cluster_data, key=bikeshop.name, value=model)
library(reshape2)
dcast(... ~ model, value.var="value")
dcast(... ~ model + sales, value.var="value")
dcast(bikeshop.id ~ model + sales, value.var="value")
dcast(... ~ model, value.var="value", data = cluster_data)
dcast(... ~ model, value.var="sales", data = cluster_data)
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
cluster_data[is.na(cluster_data)] <- 0
?apply
cluster_data <- apply(cluster_data, 2, normalize)
normalize <- function(x) {
return(x-min(x))/(max(x)-min(x))
}
cluster_data <- apply(cluster_data, 2, normalize)
cluster_data <- apply(cluster_data[, c(2:ncol(cluster_data))], 2, normalize)
normalize(cluster_data$1)
normalize(cluster_data$`Bad Habit 1`)
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
normalize(cluster_data$`Bad Habit 1`)
(cluster_data$`Bad Habit 1`-min(cluster_data$`Bad Habit 1`))/(max(cluster_data$`Bad Habit 1`)-min(cluster_data$`Bad Habit 1`))
normalize <- function(x) {
x <- (x-min(x))/(max(x)-min(x))
return(x)
}
normalize(cluster_data$`Bad Habit 1`)
cluster_data <- apply(cluster_data[, c(2:ncol(cluster_data))], 2, normalize)
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
apply(cluster_data, 2, normalize)
normalize <- function(x) {
x <- as.numeric(x)
x <- (x-min(x))/(max(x)-min(x))
return(x)
}
apply(cluster_data, 2, normalize)
apply(cluster_data, 2, class)
apply(cluster_data, 2, as.numeric)
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
# Fill NAs with 0s (NAs imply zero sales)
cluster_data <- apply(cluster_data, 2, as.numeric)
cluster_data[is.na(cluster_data)] <- 0
apply(cluster_data, 2, class)
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
# Fill NAs with 0s (NAs imply zero sales)
cluster_data <- apply(cluster_data[, c(2:ncol(cluster_data))], 2, as.numeric)
cluster_data[is.na(cluster_data)] <- 0
normalize <- function(x) {
x <- as.numeric(x)
x <- (x-min(x))/(max(x)-min(x))
return(x)
}
cluster_data <- apply(cluster_data, 2, normalize)
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
X <- select(cluster_data, -1)
y <- select(cluster_data, 1)
# Group and Reshape Data
# ----------------------
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var="sales")
X <- select(cluster_data, -1)
y <- select(cluster_data, 1)
# Fill NAs with 0s (NAs imply zero sales)
X <- apply(X, 2, as.numeric)
X[is.na(X)] <- 0
# Normalize Data
# --------------
# Scale the data with MinMax method
normalize <- function(x) {
x <- (x-min(x))/(max(x)-min(x))
return(x)
}
normalized_data <- apply(X, 2, normalize)
View(normalized_data)
corrplot(normalized_data)
n_clusters <- seq(2, 11, 1)
?sapply
n_clusters <- seq(2, 11, 1)
models <- sapply(n_clusters, function(x)(kmeans(normalized_data, x, nstart=20)))
models
n_clusters
models <- kmeans(normalized_data, 2, nstart=20)
models
models$tot.withinss
models$tot.withinss / models$sit
models$tot.withinss / models$size
models$totss
models$size
models$betweenss
models$totss
models <- kmeans(normalized_data, 3, nstart=20)
models$totss
models <- kmeans(normalized_data, 4, nstart=20)
models$totss
models$betweenss
models <- kmeans(normalized_data, 3, nstart=20)
models$betweenss
models <- kmeans(normalized_data, 2, nstart=20)
models$betweenss
models <- kmeans(normalized_data, 5, nstart=20)
models$betweenss
models$withonss
models$withinss
models$tot.withinss
models <- c(models, sapply(n_clusters, function(x)(kmeans(normalized_data, x, n_iter = 50)$withinss)))
n_clusters <- seq(2, 11, 1)
models <- c(models, sapply(n_clusters, function(x)(kmeans(normalized_data, x, iter = 50)$withinss)))
models
kmeans(normalized_data, 2, iter = 50)$withinss
models <- c(models, sapply(n_clusters, function(x)(kmeans(normalized_data, x, iter = 50)$tot.withinss)))
models
sapply(n_clusters, function(x)(kmeans(normalized_data, x, iter = 50)$tot.withinss))
models <- sapply(n_clusters, function(x)(kmeans(normalized_data, x, iter = 50)$tot.withinss))
models
n_clusters
install.packages("ggthemes")
library(ggthemes)
elbow_p <- ggplot(elbow_df, aes(x = n_clusters, y = distortion)) +
geom_line() +
ggtitle("Optimal Number of Clusters (Scree Plot/Elbow Method)") +
xlab("Number of Clusters") +
ylab('Distortion') +
theme_tufte()
elbow_df <- data.frame("n_clusters" = n_clusters, "distortion" = distortions)
elbow_p <- ggplot(elbow_df, aes(x = n_clusters, y = distortion)) +
geom_line() +
ggtitle("Optimal Number of Clusters (Scree Plot/Elbow Method)") +
xlab("Number of Clusters") +
ylab('Distortion') +
theme_tufte()
n_clusters <- seq(2, 11, 1)
distortions <- sapply(n_clusters, function(x)(kmeans(normalized_data, x, iter = 50)$tot.withinss))
elbow_df <- data.frame("n_clusters" = n_clusters, "distortion" = distortions)
elbow_p <- ggplot(elbow_df, aes(x = n_clusters, y = distortion)) +
geom_line() +
ggtitle("Optimal Number of Clusters (Scree Plot/Elbow Method)") +
xlab("Number of Clusters") +
ylab('Distortion') +
theme_tufte()
elbow_p
elbow_p <- ggplot(elbow_df, aes(x = n_clusters, y = distortion)) +
geom_line() +
scale_x_continuous(breaks = n_clusters)
ggtitle("Optimal Number of Clusters (Scree Plot/Elbow Method)") +
xlab("Number of Clusters") +
ylab('Distortion') +
theme_tufte()
elbow_p <- ggplot(elbow_df, aes(x = n_clusters, y = distortion)) +
geom_line() +
scale_x_continuous(breaks = n_clusters) +
ggtitle("Optimal Number of Clusters (Scree Plot/Elbow Method)") +
xlab("Number of Clusters") +
ylab('Distortion') +
theme_tufte()
elbow_p
install.packages("cluster")
library(cluster)
test <- as.matrix(dist(normalized_data))
labs <- kmeans(normalized_data, 3, iter = 50)$cluster
mean(silhouette(labs, dmatrix = test))
mean(silhouette(labs, dmatrix = test)[, 3])
silhouette(labels, dmatrix = data)
silhouette(as.numeric(labels), dmatrix = data)
silhouette(labs, dmatrix = data)
silhouette(labs, dmatrix = test)
silhouette(labs, dmatrix = test)[,3]
silhouette_avgs <- sapply(n_clusters, function(x)(silhouette_means(x)))
silhouette_means <- function(x) {
data <- as.matrix(dist(normalized_data))
labels <- kmeans(normalized_data, x, iter = 50)$cluster
result <- mean(silhouette(labels, dmatrix = data)[,3])
return(result)
}
silhouette_avgs <- sapply(n_clusters, function(x)(silhouette_means(x)))
silhouette_avgs
silhouette_means <- function(x) {
data <- as.matrix(dist(normalized_data))
labels <- kmeans(normalized_data, x, iter = 50)$cluster
result <- mean(silhouette(labels, dmatrix = data)[,3])
return(result)
}
silhouette_avgs <- sapply(n_clusters, function(x)(silhouette_means(x)))
silhouette_df <- data.frame("n_clusters" = n_clusters, "silhouette_score" = silhouette_avgs)
silhouette_p <- ggplot(silhouette_df, aes(x = n_clusters, y = silhouette_score)) +
geom_line() +
scale_x_continuous(breaks = n_clusters) +
ggtitle("Optimal Number of Clusters (Silhouette Method)") +
xlab("Number of Clusters") +
ylab('Silhouette Score') +
theme_tufte()
silhouette_p
explained_variance_ratio <- model.var / sum(model.var)
model <- prcomp(X, scale = TRUE)
explained_variance_ratio <- model.var / sum(model.var)
model.var <- model$sdev^2
explained_variance_ratio <- model.var / sum(model.var)
explained_variance_ratio
model <- prcomp(X, scale = TRUE)
names(model)
model$x
model$scale
mode
model
length(model$x)
class(model$x)
ncol(model$x)
seq(ncol(model$x))
pca_df <- data.frame("n_components" = seq(ncol(model$x)),
"explained_variance_ratio" = explained_variance_ratio,
"evr_cumulative" = cumsum(explained_variance_ratio))
install.packages("gridExtra")
library(gridExtra)
model.var <- model$sdev^2
explained_variance_ratio <- model.var / sum(model.var)
pca_df <- data.frame("n_components" = seq(ncol(model$x)),
"explained_variance_ratio" = explained_variance_ratio,
"evr_cumulative" = cumsum(explained_variance_ratio))
explained_variance_p1 <- ggplot(pca_df, aes(x = n_components, y = explained_variance_ratio)) +
geom_line() +
scale_x_continuous(breaks = n_clusters) +
ggtitle("Proportions of Variance Explained by each Component") +
xlab("Number of Components") +
ylab('Explained Variance Ratio') +
theme_tufte()
explained_variance_p2 <- ggplot(pca_df, aes(x = n_components, y = evr_cumulative)) +
geom_line() +
scale_x_continuous(breaks = n_clusters) +
ggtitle("Proportions of Variance Explained by each Component") +
xlab("Number of Components") +
ylab('Cumulative Explained Variance Ratio') +
theme_tufte()
grid.arrange(explained_variance_p1, explained_variance_p2)
grid.arrange(explained_variance_p1, explained_variance_p2)
explained_variance_p1 <- ggplot(pca_df, aes(x = n_components, y = explained_variance_ratio)) +
geom_line() +
scale_x_continuous(breaks = pca_df$n_components) +
ggtitle("Proportions of Variance Explained by each Component") +
xlab("Number of Components") +
ylab('Explained Variance Ratio') +
theme_tufte()
explained_variance_p2 <- ggplot(pca_df, aes(x = n_components, y = evr_cumulative)) +
geom_line() +
scale_x_continuous(breaks = pca_df$n_components) +
ggtitle("Proportions of Variance Explained by each Component") +
xlab("Number of Components") +
ylab('Cumulative Explained Variance Ratio') +
theme_tufte()
grid.arrange(explained_variance_p1, explained_variance_p2)
# Load data in memory
# -------------------
customers <- read.csv("customers_bikeshops.csv")
orders <- read.csv("orders.csv")
products <- read.csv("products_bikes.csv")
# Merge datasets
# --------------
orders_products <- inner_join(orders, products, by = c("product.id" = "bike.id"))
bike_data <- inner_join(customers, orders_products, by = c("bikeshop.id" = "customer.id"))
# Group and Reshape Data
# ----------------------
cluster_data <- group_by(bike_data, bikeshop.name, model) %>%
summarize(quantity = sum(quantity), price = sum(price)) %>%
mutate(sales = quantity * price) %>%
select(bikeshop.name, model, sales) %>%
dcast(... ~ model, value.var = "sales")
X <- select(cluster_data, -1)
y <- select(cluster_data, 1)
# Fill NAs with 0s (NAs imply zero sales)
X <- apply(X, 2, as.numeric)
X[is.na(X)] <- 0
# Normalize Data
# --------------
# Scale the data with mean = 0 and sd = 1
normalized_data <- apply(X, 2, scale)
corrplot(normalized_data)
normalized_data
View(normalized_data)
scale(X)
normalized_data <- data.frame(apply(X, 2, scale))
normalized_data
?hclust
hclust$method
match.call()
match.call(hclust)
tmpfun <- function(...) {
print(as.list(match.call()))}
tmpfun(hclust)
tmpfun(hclust(dist(normalized_data)))
tmpfun(hclust(dist(normalized_data, method = "complete")))
model_ward <- hclust(diss, method = "ward.D")
model_ward2 <- hclust(diss, method = "ward.D2")
model_single <- hclust(diss, method = "single")
model_complete <- hclust(diss, method = "complete")
model_average <- hclust(diss, method = "average")
model_mcquitty <- hclust(diss, method = "mcquitty")
model_centroid <- hclust(diss, method = "median")
model_median <- hclust(diss, method = "centroid")
diss <- dist(normalized_data)
model_ward <- hclust(diss, method = "ward.D")
model_ward2 <- hclust(diss, method = "ward.D2")
model_single <- hclust(diss, method = "single")
model_complete <- hclust(diss, method = "complete")
model_average <- hclust(diss, method = "average")
model_mcquitty <- hclust(diss, method = "mcquitty")
model_centroid <- hclust(diss, method = "median")
model_median <- hclust(diss, method = "centroid")
c(model_ward,)
c(model_ward,model_ward2)
plot(model_ward)
plot(model_ward, main = "Ward.D Linkage")
plot(model_ward, main = "Ward.D Linkage")
model_ward <- hclust(diss, method = "ward.D")
model_ward2 <- hclust(diss, method = "ward.D2")
model_single <- hclust(diss, method = "single")
model_complete <- hclust(diss, method = "complete")
model_average <- hclust(diss, method = "average")
model_mcquitty <- hclust(diss, method = "mcquitty")
model_centroid <- hclust(diss, method = "median")
model_median <- hclust(diss, method = "centroid")
par(mfrow = c(3, 3))
plot(model_ward, main = "Ward.D Linkage")
plot(model_ward2, main = "Ward.D2 Linkage")
plot(model_single, main = "Single Linkage")
plot(model_complete, main = "Complete Linkage")
plot(model_average, main = "Average Linkage")
plot(model_mcquitty, main = "McQuitty Linkage")
plot(model_centroid, main = "Centroid Linkage")
plot(model_median, main = "Median Linkage")
